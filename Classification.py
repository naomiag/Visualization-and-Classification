# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z3Zbi9ZKZnpcfpshLM7PDtNIr9eI7seW
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://downloads.apache.org/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz
!tar -xvf spark-3.0.2-bin-hadoop2.7.tgz
!pip install -q findspark
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.2-bin-hadoop2.7"
import findspark
findspark.init()

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler, StandardScaler 
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.sql.functions import when

spark = SparkSession.builder.getOrCreate()

#1 load data using spark
testing = spark.read.option("inferSchema", "True").csv("Storm_Testing.csv", header=True)
training = spark.read.option("inferSchema", "True").csv("Storm_Training.csv", header=True)

#2 select 3 features for training
testing = testing.select("atmospheric_pressure", "visible_cloud", "temperature", "storm_coming")
training = training.select("atmospheric_pressure", "visible_cloud", "temperature", "storm_coming")

#3 data processing, removing missing values
testing = testing.na.drop()
training = training.na.drop()

def process(data):

  #4 transforming data(recode the value)
  data = data.withColumn("storm_coming", when(data["storm_coming"] == "No", 0).otherwise(1))
  #data = data.withColumn("ocean_wave_speed", when(data["ocean_wave_speed"] == "Low", 0)
  #  .when(data["ocean_wave_speed"] == "High", 1)
  #  .otherwise(2))

  data = data.withColumn("visible_cloud", when(data["visible_cloud"] == "Cumulus", 0)
    .when(data["visible_cloud"] == "Stratus", 1)
    .when(data["visible_cloud"] == "Cumulonimbus", 2)
    .otherwise(3))

  data = data.withColumn("temperature", when(data["temperature"] == "Decline", 0)
    .when(data["temperature"] == "Stable", 1)
    .otherwise(2))

  
  #5 normalize the data using StandardScaler package
  columns = data.columns
  columns.remove("storm_coming")
  data = VectorAssembler(inputCols = columns, outputCol = "Feature Vector").transform(data)

  data = StandardScaler(inputCol = "Feature Vector", outputCol = "Feature").fit(data).transform(data)
  
  return data

testing = process(testing)
training = process(training)

#6 generate model  use the logisticRegressionpackage.
model = LogisticRegression(featuresCol = "Feature", labelCol = "storm_coming", maxIter = 10).fit(training)

#7 model testing and evaluation, using BinaryClassificationEvaluator package.
# the case asked the accuracy is 74% or higher

predict = model.transform(testing)

predict.select("atmospheric_pressure", "visible_cloud", "temperature", "storm_coming").show()

eval = BinaryClassificationEvaluator(labelCol = "storm_coming")

print(f'Accuracy: {eval.evaluate(predict)*100}%')